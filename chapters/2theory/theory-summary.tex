\bigskip

In this chapter, the signal model has been defined and the \gls{prp} has been identified as a measure of the \gls{tdoa} in the frequency domain. Next, the Gaussian distribution has been introduced and definitions have been presented for its real, its complex and its multivariate form. The Gaussian was mixture model was motivated by the limitation of a single Gaussian to only model unimodally distributed data and has been defined as a weighted linear combination of Gaussian components. The weighting factor of each components together with the variance is the parameter set to be estimated using the \gls{em} algorithm, which is able to determine the \gls{ml} estimates for these parameters despite incomplete data by introducing a latent variable that models the missing information. It has been shown, how the \gls{em} algorithm can be understood as a iterative lower-bound optimisation of the incomplete data log-likelihood function, where the lower-bound is considerably easier to maximise for distributions of the exponential family, than the original likelihood function. In the end, limitations of the \gls{em} algorithm and strategies to alleviate these limitations have been discussed.